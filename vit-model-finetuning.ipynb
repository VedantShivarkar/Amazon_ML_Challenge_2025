{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13351252,"sourceType":"datasetVersion","datasetId":8467617},{"sourceId":13351341,"sourceType":"datasetVersion","datasetId":8467689}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:08:20.231217Z","iopub.execute_input":"2025-10-12T14:08:20.231626Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nprint(torch.cuda.is_available())  # Should return True\nprint(torch.cuda.get_device_properties(0))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:08:37.120991Z","iopub.execute_input":"2025-10-12T14:08:37.121251Z","iopub.status.idle":"2025-10-12T14:08:38.930244Z","shell.execute_reply.started":"2025-10-12T14:08:37.121232Z","shell.execute_reply":"2025-10-12T14:08:38.929226Z"}},"outputs":[{"name":"stdout","text":"True\n_CudaDeviceProperties(name='Tesla P100-PCIE-16GB', major=6, minor=0, total_memory=16269MB, multi_processor_count=56, uuid=bcc61e3e-f44e-4103-a820-d47d74e1604f, L2_cache_size=4MB)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport math\nimport io\nimport zipfile\nimport pandas as pd\nimport requests\nfrom PIL import Image\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nfrom transformers import ViTModel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:08:38.935630Z","iopub.execute_input":"2025-10-12T14:08:38.935838Z","iopub.status.idle":"2025-10-12T14:08:46.311762Z","shell.execute_reply.started":"2025-10-12T14:08:38.935820Z","shell.execute_reply":"2025-10-12T14:08:46.311102Z"}},"outputs":[{"name":"stderr","text":"2025-10-12 14:08:43.135724: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1760278123.160226     108 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1760278123.167710     108 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# ==========================\n# DATASET FOR IMAGE URLS + PRICE\n# ==========================\nclass PriceRegressionDataset(Dataset):\n    \"\"\"\n    Dataset for image files in a directory â†’ price regression.\n    Expects a CSV with columns: sample_id, catalog_content, train_image_name, price\n    Images are stored in a directory.\n    \"\"\"\n    def __init__(self, csv_path, img_dir, transform=None, cache_dir=\"image_cache\"):\n        self.df = pd.read_csv(csv_path)\n        self.img_dir = img_dir\n        self.transform = transform\n        self.cache_dir = cache_dir\n        os.makedirs(cache_dir, exist_ok=True)\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        image_name = row[\"train_image_name\"]\n        target = torch.tensor([row[\"price\"]], dtype=torch.float32)\n        # cache filename by sample_id\n        fname = os.path.join(self.cache_dir, f\"{row['sample_id']}.jpg\")\n        if not os.path.exists(fname):\n            img_path = os.path.join(self.img_dir, image_name)\n            img = Image.open(img_path).convert(\"RGB\")\n            img.save(fname)\n        else:\n            img = Image.open(fname).convert(\"RGB\")\n        if self.transform:\n            img = self.transform(img)\n        else:\n            img = transforms.ToTensor()(img)\n        return img, target\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:08:46.312681Z","iopub.execute_input":"2025-10-12T14:08:46.313234Z","iopub.status.idle":"2025-10-12T14:08:46.320676Z","shell.execute_reply.started":"2025-10-12T14:08:46.313210Z","shell.execute_reply":"2025-10-12T14:08:46.319815Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"\n# ==========================\n# VISION TRANSFORMER REGRESSION MODEL\n# ==========================\nclass ViTRegressionModel(nn.Module):\n    def __init__(self,\n                 model_name='google/vit-base-patch16-224',\n                 num_outputs=1,\n                 freeze_backbone=False,\n                 dropout_rate=0.1):\n        super().__init__()\n        self.vit = ViTModel.from_pretrained(model_name)\n        if freeze_backbone:\n            for p in self.vit.parameters():\n                p.requires_grad = False\n        hidden_size = self.vit.config.hidden_size\n        self.reg_head = nn.Sequential(\n            nn.Dropout(dropout_rate),\n            nn.Linear(hidden_size, hidden_size // 2),\n            nn.ReLU(),\n            nn.Dropout(dropout_rate),\n            nn.Linear(hidden_size // 2, num_outputs)\n        )\n    def forward(self, pixel_values):\n        out = self.vit(pixel_values=pixel_values)\n        cls_feat = out.last_hidden_state[:, 0, :]\n        return self.reg_head(cls_feat)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:08:46.321759Z","iopub.execute_input":"2025-10-12T14:08:46.322517Z","iopub.status.idle":"2025-10-12T14:08:46.345984Z","shell.execute_reply.started":"2025-10-12T14:08:46.322489Z","shell.execute_reply":"2025-10-12T14:08:46.345133Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"\n# ==========================\n# TRAIN / EVAL FUNCTIONS\n# ==========================\ndef train(model, loader, val_loader, device, epochs=5, lr=1e-4):\n    model.to(device)\n    optim_ = optim.AdamW(model.parameters(), lr=lr, weight_decay=0.01)\n    crit = nn.MSELoss()\n    sched = optim.lr_scheduler.StepLR(optim_, step_size=2, gamma=0.8)\n    for ep in range(epochs):\n        model.train()\n        total, count = 0.0, 0\n        for imgs, tgts in loader:\n            imgs, tgts = imgs.to(device), tgts.to(device)\n            optim_.zero_grad()\n            pred = model(imgs)\n            loss = crit(pred, tgts)\n            loss.backward()\n            optim_.step()\n            total += loss.item() * imgs.size(0)\n            count += imgs.size(0)\n        train_rmse = math.sqrt(total / count)\n        model.eval()\n        total_val, count_val = 0.0, 0\n        with torch.no_grad():\n            for imgs, tgts in val_loader:\n                imgs, tgts = imgs.to(device), tgts.to(device)\n                pred = model(imgs)\n                total_val += crit(pred, tgts).item() * imgs.size(0)\n                count_val += imgs.size(0)\n        val_rmse = math.sqrt(total_val / count_val)\n        print(f\"Epoch {ep+1}/{epochs} Train RMSE: {train_rmse:.4f} Val RMSE: {val_rmse:.4f}\")\n        sched.step()\n\ndef evaluate(model, loader, device):\n    model.to(device).eval()\n    preds, tgts = [], []\n    with torch.no_grad():\n        for imgs, tgt in loader:\n            imgs = imgs.to(device)\n            out = model(imgs).cpu()\n            preds.append(out)\n            tgts.append(tgt)\n    preds = torch.cat(preds).squeeze().numpy()\n    tgts = torch.cat(tgts).squeeze().numpy()\n    rmse = math.sqrt(((preds - tgts) ** 2).mean())\n    print(f\"Test RMSE: {rmse:.4f}\")\n    return preds, tgts","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:08:46.347284Z","iopub.execute_input":"2025-10-12T14:08:46.347581Z","iopub.status.idle":"2025-10-12T14:08:46.368016Z","shell.execute_reply.started":"2025-10-12T14:08:46.347552Z","shell.execute_reply":"2025-10-12T14:08:46.367079Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# # ==========================\n# # MAIN SCRIPT\n# # ==========================\n# if __name__ == \"__main__\":\n#     CSV_PATH = \"/kaggle/input/vit-train-csv/VIT_train_subset.csv\" # path to your CSV file\n#     IMG_DIR = \"/kaggle/input/vit-images-train/train_images\" # path to your image directory\n#     BATCH_SIZE = 16\n#     IMG_SIZE = 224\n#     # Transforms\n#     transform = transforms.Compose([\n#         transforms.Resize((IMG_SIZE, IMG_SIZE)),\n#         transforms.ToTensor(),\n#         transforms.Normalize([0.485,0.456,0.406],\n#                              [0.229,0.224,0.225])\n#     ])\n#     # Dataset & Dataloaders\n#     dataset = PriceRegressionDataset(CSV_PATH, IMG_DIR, transform=transform)\n#     n = len(dataset)\n#     n_train = int(0.7 * n)\n#     n_val = int(0.15 * n)\n#     n_test = n - n_train - n_val\n#     train_ds, val_ds, test_ds = torch.utils.data.random_split(\n#         dataset, [n_train, n_val, n_test],\n#         generator=torch.Generator().manual_seed(42)\n#     )\n#     train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n#     val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n#     test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n#     # Model, training, evaluation\n#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n#     model = ViTRegressionModel(freeze_backbone=False)\n#     train(model, train_loader, val_loader, device, epochs=5, lr=1e-4)\n#     evaluate(model, test_loader, device)\n#     # Save model\n#     torch.save(model.state_dict(), \"/kaggle/working/vit_price_regression.pth\")\n#     print(\"Saved model to vit_price_regression.pth\")\n   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:08:46.368891Z","iopub.execute_input":"2025-10-12T14:08:46.369299Z","iopub.status.idle":"2025-10-12T14:08:46.388964Z","shell.execute_reply.started":"2025-10-12T14:08:46.369276Z","shell.execute_reply":"2025-10-12T14:08:46.388102Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    CSV_PATH = \"/kaggle/input/vit-train-csv/VIT_train_subset.csv\" # path to your CSV file\n    IMG_DIR = \"/kaggle/input/vit-images-train/train_images\" # path to your image directory\n    BATCH_SIZE = 16\n    IMG_SIZE = 224\n    # Transforms\n    transform = transforms.Compose([\n        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485,0.456,0.406],\n                             [0.229,0.224,0.225])\n    ])\n    print(\"Loading dataset...\")\n    # Dataset & Dataloaders\n    dataset = PriceRegressionDataset(CSV_PATH, IMG_DIR, transform=transform)\n    print(f\"Dataset loaded with {len(dataset)} samples.\")\n    n = len(dataset)\n    n_train = int(0.7 * n)\n    n_val = int(0.15 * n)\n    n_test = n - n_train - n_val\n    print(f\"Splitting dataset: Train={n_train}, Val={n_val}, Test={n_test}\")\n    train_ds, val_ds, test_ds = torch.utils.data.random_split(\n        dataset, [n_train, n_val, n_test],\n        generator=torch.Generator().manual_seed(42)\n    )\n    train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n    val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n    test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n    print(\"Data loaders created.\")\n    # Model, training, evaluation\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Using device: {device}\")\n    model = ViTRegressionModel(freeze_backbone=False)\n    print(\"Starting training...\")\n    train(model, train_loader, val_loader, device, epochs=5, lr=1e-4)\n    print(\"Training completed.\")\n    print(\"Evaluating model...\")\n    evaluate(model, test_loader, device)\n    print(\"Evaluation completed.\")\n    # Save model\n    torch.save(model.state_dict(), \"/kaggle/working/vit_price_regression.pth\")\n    print(\"Saved model to vit_price_regression.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-12T14:08:46.389923Z","iopub.execute_input":"2025-10-12T14:08:46.390306Z","iopub.status.idle":"2025-10-12T14:42:43.379842Z","shell.execute_reply.started":"2025-10-12T14:08:46.390280Z","shell.execute_reply":"2025-10-12T14:42:43.378903Z"}},"outputs":[{"name":"stdout","text":"Loading dataset...\nDataset loaded with 25004 samples.\nSplitting dataset: Train=17502, Val=3750, Test=3752\nData loaders created.\nUsing device: cuda\n","output_type":"stream"},{"name":"stderr","text":"Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Starting training...\nEpoch 1/5 Train RMSE: 30.7800 Val RMSE: 27.5115\nEpoch 2/5 Train RMSE: 29.7328 Val RMSE: 27.0518\nEpoch 3/5 Train RMSE: 29.0698 Val RMSE: 26.8701\nEpoch 4/5 Train RMSE: 28.3197 Val RMSE: 26.7390\nEpoch 5/5 Train RMSE: 26.2783 Val RMSE: 27.5460\nTraining completed.\nEvaluating model...\nTest RMSE: 28.4041\nEvaluation completed.\nSaved model to vit_price_regression.pth\n","output_type":"stream"}],"execution_count":8}]}